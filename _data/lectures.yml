- date: M 08/25
  lecturer: 
  title: >
    <strong>Welcome and Introduction to the Class</strong>
  slides: https://drive.google.com/file/d/17oWZGJJQOoeb8i1-S3H-Qz-iw2ZWJB1i/view?usp=drive_link
  slides2: https://www.dropbox.com/scl/fi/03ant3g0t8kqeqaz5lo5w/lecture1_introF25.pdf?rlkey=6lu21m7yaz63e8r29ecpw1mcp&dl=0
  video:
  notes:
  readings:
    - <a href="http://incompleteideas.net/book/RLbook2018.pdf" target="_blank">S & B Textbook</a>, Ch1
    - (optional) Smith & Gasser. <a href="https://cogdev.sitehost.iu.edu/labwork/6_lessons.pdf" target="_blank">The Development of Embodied Cognition - Six Lessons from Babies</a>
    - (optional) Dan Wolpert't talk <a href="https://www.ted.com/talks/daniel_wolpert_the_real_reason_for_brains/transcript?language=en#t-1117820" target="blank">The real reason for brains</a>
  logistics:

- date: W 08/27
  lecturer: 
  title: >
    <strong>Introduction to Reinforcement Learning</strong>
  slides: https://drive.google.com/file/d/1B-zhUfhpnZAnHye92VK8vKhaBHGIs2by/view?usp=sharing
  slides2:
  video:
  notes:
  readings:
     - <a href="http://incompleteideas.net/book/RLbook2018.pdf" target="_blank">S & B Textbook</a>, Ch1
    #- Russo et al. <a href="https://arxiv.org/abs/1707.02038" target="_blank">A Tutorial on Thompson Sampling</a>, Ch1-Ch4. Optional after Ch4
    #- (optional) Aleksandrs Slivkins <a href="https://arxiv.org/pdf/1904.07272">Introduction to Multi-Armed Bandits</a>
  logistics:

- date: F 08/29
  lecturer:
  title:
  recitation: >
    <strong>Neural Nets, PyTorch, Gymnasium </strong>
  slides: https://docs.google.com/presentation/d/1BFxauyrZsh25aKA5toAlYl5pQtKXpXyu/edit?usp=sharing&ouid=115850382795288871894&rtpof=true&sd=true
  notes: https://drive.google.com/file/d/1BX9zooXG8Z08HBOviS8mMzG7gFlIFvT_/view?usp=sharing
  video:
  readings:
    - <a href="https://www.deeplearningbook.org/" target="_blank">G, B & C Textbook</a>, Ch9, Ch10
    - Gym tutorial <a href="https://colab.research.google.com/drive/1qlqJ3LqpOO8E-6HyPyjiuC80Z7GWgTSv?usp=sharing" target=  "_blank">notebook</a>
    - PyTorch tutorial <a href="https://colab.research.google.com/drive/1-3hN0C9grsg62KoeFIxywcPum4a-HAYk?usp=sharing" target=  "_blank">notebook</a>
  logistics:



- date: M 09/01
  lecturer: 
  quiz: >
    <strong>No Class, Labor Day</strong>
  logistics:


- date: W 09/03
  lecturer: 
  title: >
    <strong>Policy Gradient Methods </strong>
  slides: https://www.dropbox.com/scl/fi/wgm80d9kv4uezbb6yhig6/PG_F25.pdf?rlkey=ivscy52a2u96piohk84so9x1s&dl=0
  video:
  notes:
  readings:
    - <a href="https://www.deeplearningbook.org/" target="_blank">G, B & C Textbook</a>, Ch13
    - <a href="http://karpathy.github.io/2016/05/31/rl/" target = "_blank">http://karpathy.github.io/2016/05/31/rl/</a>
  logistics: <span class="event">HW1 out </span> <br>


- date: F 09/05
  lecturer:
  title:
  recitation: >
    <strong>MDPs, Policy Gradients, & HW1 </strong>
  slides: https://drive.google.com/file/d/1uP_ZkxWA3izMrfB9kTAQICeslAr4Qpoa/view?usp=sharing
  slides2:
  notes: 
  video:
  readings:
  logistics:


- date: M 09/08
  lecturer: 
  title: >
    <strong>Actor-Critic Methods (cont.) Evolutionary Methods for Policy Search</strong>
  slides: https://www.dropbox.com/scl/fi/wgm80d9kv4uezbb6yhig6/PG_F25.pdf?rlkey=ivscy52a2u96piohk84so9x1s&dl=0
  slides2: https://www.dropbox.com/scl/fi/0yw9xsu8ld9gfd90toxy0/evolutionarymethods_F25.pdf?rlkey=wey3k9wswrp6vkfdb6v0whtfy&dl=0
  video:
  notes:
  readings:
    - Mnih et al. <a href="https://arxiv.org/abs/1602.01783">Asynchronous Methods for Deep Reinforcement Learning</a>
    - Salimans et al. <a href="https://arxiv.org/pdf/1703.03864.pdf"> Evolution Strategies as a Scalable Alternative to Reinforcement Learning</a>
    - (optional) <a href="https://arxiv.org/pdf/1604.00772.pdf">Nikolaus Hansen. The CMA Evolution Strategy - A Tutorial</a>
  logistics: 


- date: W 09/10
  lecturer: 
  title: >
    <strong>Value-based Methods</strong>
  slides: https://drive.google.com/file/d/1IDYQkudBASIt6pihxMtg_PVHQuH_KgV3/view?usp=sharing
  slides2: https://drive.google.com/file/d/1uqiF066FOdmy9ZBIogGnzYrV0Fj9PAon/view?usp=sharing
  video:
  notes:
  readings:
    - Mnih et al. <a href="https://arxiv.org/abs/1312.5602"> Playing Atari with Deep Reinforcement Learning </a>
    - Martin Riedmiller <a href="https://link.springer.com/chapter/10.1007/11564096_32"> Neural Fitted Q-Iteration </a>
    - Fu et al. <a href="https://arxiv.org/abs/1902.10250"> Diagnosing Bottlenecks in Deep Q-learning Algorithms </a>
    # - <a href="http://incompleteideas.net/book/RLbook2018.pdf" target="_blank">S & B Textbook</a>, Ch3, Ch4
    # - <a href="http://incompleteideas.net/book/RLbook2018.pdf" target="_blank">S & B Textbook</a>, Ch5, Ch6
    # - <a href="https://distill.pub/2019/paths-perspective-on-value-learning/" target="blank">(optional) The Path perspective on Value Learning </a> (blogpost)
  logistics: 



- date: F 09/12
  lecturer:
  title:
  recitation: >
    <strong> Value-Based Methods and Actor-Critic Methods </strong>
  slides: https://docs.google.com/presentation/d/1JLpRyM61YEP2XNwbdb1YL8j33wWdCgjpEHxOuLIRDIs/edit?usp=sharing
  slides2:
  notes: 
  video:
  readings:
  logistics: <span class="deadline">HW1 Due</span>, <span class="event">HW2 out </span> <br>



- date: M 09/15
  lecturer: 
  title: >
    <strong>Value based methods (Cont.)</strong>
  slides: https://drive.google.com/file/d/1ggsDK2kQRpryZGIEsaRd0yq04Ux7k1m0/view?usp=sharing
  slides2: https://drive.google.com/file/d/1urLD6LkJVIGkgvSbBhURRTffsHo5V19n/view?usp=sharing
  video:
  notes:
  readings:
    - <a href="https://arxiv.org/abs/1509.06461">Deep Reinforcement Learning with Double Q-learning</a>
    - <a href="http://incompleteideas.net/book/RLbook2018.pdf" target="_blank">S & B Textbook</a>, Ch8.11
    - <a href="https://arxiv.org/abs/2403.03950">Stop Regressing - Training Value Functions via Classification for Scalable Deep RL</a>
    - <a href="https://jmlr.org/papers/v15/dann14a.html">(optional) Policy Evaluation with Temporal Differences&#58; A Survey and Comparison</a>
    - <a href="https://arxiv.org/abs/1707.06887">(optional) A Distributional Perspective on Reinforcement Learning</a>

  logistics: 



- date: W 09/17
  lecturer:
  title: >
    <strong> Advanced Policy Gradient Methods </strong>
  recitation: 
  slides: https://drive.google.com/file/d/1usgc5dQWHxS5cGUli_2h2ZYXPFSYZ5IY/view?usp=sharing
  video:
  notes:
  readings:
    - <a href="https://people.eecs.berkeley.edu/~pabbeel/cs287-fa09/readings/KakadeLangford-icml2002.pdf"> Approximately Optimal Approximate RL </a>
    - <a href="https://arxiv.org/abs/1910.00177"> Advantage-weighted regression </a>
    - <a href="https://arxiv.org/abs/1707.06347"> Proximal Policy Optimization Algorithms </a>
    
  logistics:


- date: F 09/19
  lecturer:
  title:
  recitation: >
     <strong> Lecture 7b Advanced Policy Gradient Methods (Cont.)</strong>
  slides: https://drive.google.com/file/d/1usgc5dQWHxS5cGUli_2h2ZYXPFSYZ5IY/view?usp=sharing
  slides2: https://drive.google.com/file/d/1usk2oT67O7rqRze0PVZX-Gmko3EjynCE/view?usp=sharing
  notes: 
  video:
  readings:
    - <a href="https://people.eecs.berkeley.edu/~pabbeel/cs287-fa09/readings/KakadeLangford-icml2002.pdf"> Approximately Optimal Approximate RL </a>
    - <a href="https://arxiv.org/abs/1910.00177"> Advantage-weighted regression </a>
    - <a href="https://arxiv.org/abs/1707.06347"> Proximal Policy Optimization Algorithms </a>
  logistics: <span class="deadline">HW2 Due</span>,  <br> <span>Video Recitation HW3 </span>

- date: M 09/22
  lecturer: 
  title: >
    <strong> Advanced Policy Gradient Methods (Cont.)</strong>
  slides: https://drive.google.com/file/d/1utVQevOJm46laH_4eVel4DSiy9E1BnaD/view?usp=sharing
  readings:
    -  <a href="https://arxiv.org/abs/1707.06347"> Proximal Policy Optimization Algorithms </a>
    -  <a href="https://arxiv.org/abs/1509.02971"> Continuous control with deep reinforcement learning </a>
    -  <a href="https://arxiv.org/abs/1802.09477"> Addressing Function Approximation Error in Actor-Critic Methods </a>    
  video:
  logistics: <span class="event">HW3 Out </span>

- date: W 09/24
  lecturer: 
  title: >
    <strong>Model-based Methods</strong>
  slides: 
  video:
  readings:
    - Janner et al. <a href="https://arxiv.org/abs/2205.09991" target="_blank">Planning with Diffusion for Flexible Behavior Synthesis</a>
    - Chua et al. <a href="https://arxiv.org/abs/1805.12114" target="_blank">Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models</a>
    - Janner et al. <a href="https://arxiv.org/abs/1906.08253" target="_blank">Model-based policy optimization</a>
    - Hafner et al. <a href="https://arxiv.org/abs/2301.04104" target="_blank">Dreamer</a>
  logistics: 

- date: F 09/26
  lecturer:
  title:
  recitation: >
    <strong> Midterm Review and HW4 </strong>
  slides: 
  video:
  notes:
  readings:
  logistics:


- date: M 09/29
  lecturer: 
  title: >
    <strong>Model-based Methods(Cont.)</strong>
  slides: 
  video:
  readings:
    - Janner et al. <a href="https://arxiv.org/abs/2205.09991" target="_blank">Planning with Diffusion for Flexible Behavior Synthesis</a>
    - Chua et al. <a href="https://arxiv.org/abs/1805.12114" target="_blank">Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models</a>
    - Janner et al. <a href="https://arxiv.org/abs/1906.08253" target="_blank">Model-based policy optimization</a>
    - Hafner et al. <a href="https://arxiv.org/abs/2301.04104" target="_blank">Dreamer</a>
  logistics:


- date: T 09/30
  lecturer: 
  title: >
    <strong>Project Description Out (tentative)</strong> 
  slides: 
  video:
  notes:
  readings:
  logistics: <span class="event">Project Description Out (tentative)</span> <br>

- date: W 10/01
  lecturer: 
  title: >
    <strong>Imitation Learning</strong>
  slides: 
  video:
  notes:
  readings:
    - (optional) Chen et al. <a href="https://arxiv.org/abs/1912.12294" target="_blank">Learning by Cheating</a>
    - Bagnell. <a href="http://www.ri.cmu.edu/publication_view.html?pub_id=7891" target="_blank">An Invitation to Imitation</a>, Up To Page 10
    - Bojarski et al. <a href="https://arxiv.org/abs/1604.07316" target="_blank">End to End Learning for Self-Driving Cars</a>
  logistics: <span class="event">HW3 Due </span>,  <span class="deadline">HW4 Out </span>, <br>


- date: F 10/03
  lecturer:
  title:
  recitation: >
    <strong> Midterm </strong>
  slides: 
  video:
  notes:
  readings:
  logistics: 


- date: M 10/06
  lecturer: 
  title: >
     <strong>Imitation Learning(Cont.)</strong>
  slides: 
  slides2:
  video:
  readings:
    - Peng et al. <a href="https://arxiv.org/abs/1810.03599" target="_blank">SFV Reinforcement Learning of Physical Skills from Videos</a>
    - Baker et al. <a href="https://arxiv.org/abs/2206.11795" target="_blank">Video PreTraining (VPT):Learning to Act by Watching Unlabeled Online Videos</a>

  logistics: 



- date: W 10/08
  lecturer: 
  title: >
    <strong>Buffer</strong>
  slides: 
  video:
  notes:
  readings:
  logistics:  

- date: F 10/10
  lecturer:
  title:
  recitation: >
    <strong> IL Diffusion Policies and HW5 </strong>
  slides: 
  video:
  notes:
  readings:
  logistics: 

- date: S 10/12
  logistics: <span class="deadline">HW4 Due</span>, <span class="event">HW5 Out </span>

- date: M 10/13
  lecturer:
  quiz: >
    <strong>Fall Break - No Classes</strong>
  logistics:  


- date: W 10/15
  lecturer:
  quiz: >
    <strong>Fall Break - No Classes</strong>
  logistics:


- date: F 10/17
  lecturer:
  quiz: >
    <strong>Fall Break - No Classes</strong>
  logistics:


- date: M 10/20
  lecturer: 
  title: >
    <strong>Buffer</strong>
  slides: 
  slides2:
  video:
  notes:
  readings:


- date: W 10/22
  lecturer: 
  title: >
    <strong>Offline RL</strong>
  slides: 
  video:
  notes:
  readings:
    - Kumar et al. <a href="https://arxiv.org/abs/1906.00949"> Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction </a>
    - Kumar et al. <a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2023/EECS-2023-223.pdf"> Reinforcement Learning from Static Datasets (Chapters 1 to 5) </a>
    - Fujimoto et al. <a href="https://arxiv.org/abs/1812.02900" target="_blank">Off-Policy Deep Reinforcement Learning without Exploration</a>
    - Kumar and Levine <a href="https://sites.google.com/view/offlinerltutorial-neurips2020/home"> Offline RL Tutorial, NeurIPS 2020 </a>
 
  logistics:  



- date: F 10/24
  lecturer:
  title:
  recitation: >
    <strong> TBD </strong>
  slides: 
  video:
  notes:
  readings:
  logistics: <span class="deadline">Project Team Formation and Project Proposal Due (tentative)</span> <br>


- date: M 10/27
  lecturer: 
  title: >
    <strong>Offline RL (Cont.)</strong>
  slides: 
  video:
  notes:
  readings:
    - Kumar et al. <a href="https://arxiv.org/abs/1906.00949"> Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction </a>
    - Kumar et al. <a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2023/EECS-2023-223.pdf"> Reinforcement Learning from Static Datasets (Chapters 1 to 5) </a>
    - Fujimoto et al. <a href="https://arxiv.org/abs/1812.02900" target="_blank">Off-Policy Deep Reinforcement Learning without Exploration</a>
    - Kumar and Levine <a href="https://sites.google.com/view/offlinerltutorial-neurips2020/home"> Offline RL Tutorial, NeurIPS 2020 </a>
 
  logistics: <span class="deadline">HW5 Due</span>, <span class="event">HW6 Out (tentative)</span> <br>


- date: W 10/29
  lecturer:
  title: >
    <strong>Exploration</strong>
  slides:
  video:
  notes:
  readings:
    - Pathak et al. <a href="https://arxiv.org/abs/1705.05363" target="_blank">Curiosity-driven Exploration by Self-supervised Prediction</a>
    - Burda et al. <a href="https://arxiv.org/abs/1810.12894" target="_blank">Exploration by Random Network Distillation</a>
    
  logistics:  

- date: F 10/31
  lecturer:
  title:
  recitation: >
    <strong> TBD </strong>
  slides: 
  video:
  notes:
  readings:
  logistics:


- date: M 11/03
  lecturer: 
  title: >
    <strong>Exploration (Cont.)</strong>
  slides: 
  video:
  notes:
  readings:
    - Pathak et al. <a href="https://arxiv.org/abs/1705.05363" target="_blank">Curiosity-driven Exploration by Self-supervised Prediction</a>
    - Burda et al. <a href="https://arxiv.org/abs/1810.12894" target="_blank">Exploration by Random Network Distillation</a>
  logistics:

- date: W 11/05
  lecturer:
  title: >
    <strong>Sim2Real Learning</strong>
  slides: 
  readings:
    - Akkaya et al. <a href="https://arxiv.org/pdf/1910.07113.pdf" target="_blank">Solving Rubik’s Cube with A Robot Hand</a>
    - Kumar et al. <a href="https://arxiv.org/abs/2107.04034" target="_blank">Rapid Motor Adaptation for Legged Robots</a>
    - Tobin et al. <a href="https://arxiv.org/abs/1703.06907" target="_blank">Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World</a>
  logistics:
   

- date: F 11/07
  lecturer:
  title:
  recitation: >
    <strong> TBD </strong>
  slides: 
  video:
  notes:
  readings:
    
  logistics:

- date: M 11/10
  lecturer: 
  title: >
    <strong>Sim2Real Learning (Cont.)</strong>
  slides: 
  
  video:
  notes:
  readings:
    - Akkaya et al. <a href="https://arxiv.org/pdf/1910.07113.pdf" target="_blank">Solving Rubik’s Cube with A Robot Hand</a>
    - Kumar et al. <a href="https://arxiv.org/abs/2107.04034" target="_blank">Rapid Motor Adaptation for Legged Robots</a>
    - Tobin et al. <a href="https://arxiv.org/abs/1703.06907" target="_blank">Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World</a>

  logistics: <span class="deadline">HW6 Due</span>, <span class="event">HW7 Out (tentative)</span> <br>


- date: W 11/12
  lecturer: 
  title: >
    <strong>RL with Foundation Models</strong>
  quiz: 
  slides:
  video:
  notes:
  readings:
    - Ouyang et al. <a href="https://arxiv.org/abs/2203.02155" target="_blank">Training language models to follow instructions with human feedback</a>
    - Slides <a href="https://web.stanford.edu/class/cs234/CS234Spr2024/slides/dpo_slides.pdf" target="_blank">Direct Preference Optimization&#58; A New RLHF Approach</a>
    - Xu et al. <a href="https://arxiv.org/abs/2404.10719" target="_blank">Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study</a>
    
  logistics:



- date: F 11/14
  lecturer:
  title:
  recitation: >
    <strong> TBD </strong>
  slides: 
  video:
  notes:
  readings:
  logistics: <span class="deadline"> Project Midway Report Due (tentative)</span> <br>


- date: M 11/17
  lecturer: 
  title: >
    <strong>RL with Foundation Models (Cont.)</strong>
  slides: 
  notes:
  readings:
    - Ouyang et al. <a href="https://arxiv.org/abs/2203.02155" target="_blank">Training language models to follow instructions with human feedback</a>
    - Slides <a href="https://web.stanford.edu/class/cs234/CS234Spr2024/slides/dpo_slides.pdf" target="_blank">Direct Preference Optimization&#58; A New RLHF Approach</a>
    - Xu et al. <a href="https://arxiv.org/abs/2404.10719" target="_blank">Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study</a>
    
  logistics:  
  
  
- date: W 11/19
  title: >
    <strong>Generative Models for RL</strong>
  slides: 
  video:
  notes:
  readings:
    - Luo <a href="https://arxiv.org/abs/2208.11970" target="_blank">Understanding Diffusion Models:A Unified Perspective</a>
    - Pearce et al. <a href="https://arxiv.org/abs/2301.10677" target="_blank">Imitating Human Behaviour with Diffusion Models</a>
  logistics:

- date: F 11/21
  lecturer:
  title:
  recitation: >
    <strong> TBD </strong>
  slides: 
  video:
  notes:
  readings:
  logistics: 

- date: M 11/24
  lecturer:
  recitation: >
    <strong>Generative Models for RL (Cont.)</strong>
  slides: 
  slides2: 
  video:
  notes:
  readings:
  logistics: <span class="deadline">HW7 Due (tentative)</span> <br>
  

- date: W 11/26
  lecturer:
  quiz: >
    <strong>Thanksgiving Break - No Classes</strong>
  logistics:

- date: F 11/28
  lecturer:
  title:
  recitation: >
    <strong> Thanksgiving Break - No Recitation </strong>
  slides: 
  video:
  notes:
  readings:
  logistics:

  
- date: M 12/01
  lecturer:
  title: >
    <strong>Guest Lecture</strong>
  slides: 
  video:
  notes:
  readings:
    
  logistics:


- date: W 12/03
  lecturer:
  title: >
    <strong>Course Review</strong>
  slides: 
  
  video:
  notes:
  readings:
  logistics: 


- date: F 12/05
  lecturer:
  title:
  recitation: >
    <strong> TBD </strong>
  slides: 
  video:
  notes:
  readings:
  logistics:


- date: Finals Week
  lecturer:
  quiz: 
  #slides: 
  notes: 
  readings:
  logistics: <span class="deadline"> Project Final Poster/Report due </span> <br>
